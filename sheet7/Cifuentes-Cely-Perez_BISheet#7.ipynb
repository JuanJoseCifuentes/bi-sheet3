{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from representatives import kMeans # you can use this kMeans in Ex. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerativeClustering(D, dist, k=1):\n",
    "    C = [[i] for i in range(len(D))]\n",
    "\n",
    "    while len(C) > k:\n",
    "        distances = np.zeros((len(C), len(C)))\n",
    "        for i in range(len(C)):\n",
    "            for j in range(i + 1, len(C)):\n",
    "                distances[i][j] = dist(D, C[i], C[j])\n",
    "                distances[j][i] = distances[i][j]\n",
    "\n",
    "        min_dist = np.inf\n",
    "        min_i, min_j = None, None\n",
    "\n",
    "        for i in range(len(C)):\n",
    "            for j in range(i + 1, len(C)):\n",
    "                if distances[i][j] < min_dist:\n",
    "                    min_dist = distances[i][j]\n",
    "                    min_i, min_j = i, j\n",
    "\n",
    "        Ci, Cj = C[min_i], C[min_j]\n",
    "        Cij = []\n",
    "        Cij.extend(Ci)\n",
    "        Cij.extend(Cj)\n",
    "\n",
    "        C.remove(Ci)\n",
    "        C.remove(Cj)\n",
    "        C.append(Cij)\n",
    "\n",
    "    C.sort(key=sortFunction)\n",
    "    cluster_ids = [-1] * len(D)\n",
    "    for i, cluster in enumerate(C):\n",
    "        for point in cluster:\n",
    "            cluster_ids[point] = i\n",
    "\n",
    "    return cluster_ids\n",
    "\n",
    "def sortFunction(elem):\n",
    "    return min(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleLink(D, Ci, Cj):\n",
    "    min_dist = float()\n",
    "    for i in Ci:\n",
    "        for j in Cj:\n",
    "            dist_ij = np.linalg.norm(D[i] - D[j])\n",
    "            if dist_ij < min_dist:\n",
    "                min_dist = dist_ij\n",
    "    return min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeLink(D, Ci, Cj):\n",
    "    max_dist = 0\n",
    "    for i in Ci:\n",
    "        for j in Cj:\n",
    "            dist_ij = np.linalg.norm(D[i] - D[j])\n",
    "            if dist_ij > max_dist:\n",
    "                max_dist = dist_ij\n",
    "    return max_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupAverage(D, Ci, Cj):\n",
    "    distance_sum = 0\n",
    "\n",
    "    D_i = [D[i] for i in Ci]\n",
    "    D_j = [D[i] for i in Cj]\n",
    "\n",
    "    for point_i in D_i:\n",
    "        for point_j in D_j:\n",
    "            distance_sum += np.linalg.norm(point_i - point_j)\n",
    "\n",
    "    return distance_sum / (len(D_i) * len(D_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanDistance(D, Ci, Cj):\n",
    "    D_i = [D[i] for i in Ci]\n",
    "    D_j = [D[i] for i in Cj]\n",
    "\n",
    "    miu_i = np.average(D_i, axis=0)\n",
    "    miu_j = np.average(D_j, axis=0)\n",
    "\n",
    "    return np.linalg.norm(miu_j - miu_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ward(D, Ci, Cj):\n",
    "    D_i = [D[i] for i in Ci]\n",
    "    D_j = [D[i] for i in Cj]\n",
    "\n",
    "    miu_i = np.average(D_i, axis=0)\n",
    "    miu_j = np.average(D_j, axis=0)\n",
    "\n",
    "    mean_distance = np.linalg.norm(miu_j - miu_i)\n",
    "\n",
    "    n_i = len(D_i)\n",
    "    n_j = len(D_j)\n",
    "\n",
    "    return (((n_i * n_j) / (n_i + n_j)) * (mean_distance**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerativeClusteringLW(D, dist, k=1):\n",
    "    C = [[i] for i in range(len(D))]\n",
    "\n",
    "    distances = np.zeros((len(C), len(C)))\n",
    "    for i in range(len(C)):\n",
    "        for j in range(i + 1, len(C)):\n",
    "            distances[i][j] = np.linalg.norm(D[i] - D[j])\n",
    "            distances[j][i] = distances[i][j]\n",
    "\n",
    "\n",
    "    while len(C) > k:              \n",
    "        min_dist = np.inf\n",
    "        min_i, min_j = None, None\n",
    "\n",
    "        for i in range(len(C)):\n",
    "            for j in range(i + 1, len(C)):\n",
    "                if distances[i][j] < min_dist:\n",
    "                    min_dist = distances[i][j]\n",
    "                    min_i, min_j = i, j\n",
    "\n",
    "        Ci, Cj = C[min_i], C[min_j]\n",
    "        Cij = []\n",
    "        Cij.extend(Ci)\n",
    "        Cij.extend(Cj)\n",
    "\n",
    "        C.remove(Ci)\n",
    "        C.remove(Cj)\n",
    "        C.append(Cij)\n",
    "\n",
    "        n_i = len(Ci)\n",
    "        n_j = len(Cj)\n",
    "        n_r = 0\n",
    "\n",
    "        new_column = []\n",
    "        for r in range(C-1):\n",
    "            n_r = len(C[r])\n",
    "            a_i, a_j, b, gamma = lanceWilliamsParams(dist, n_i, n_j, n_r)\n",
    "            \n",
    "            new_distance = a_i * distances[min_i][r] + a_j * distances[min_j][r] + b * distances[min_i][min_j] + gamma * np.abs(distances[min_i][r] - distances[min_j][r])\n",
    "            new_column.append(new_distance)\n",
    "\n",
    "        distances = np.delete(distances, [min_i,min_j], 0)\n",
    "        distances = np.delete(distances, [min_i,min_j], 1)\n",
    "\n",
    "        distances = np.insert(distances, len(distances), new_column, 0)\n",
    "        new_column.append(0)\n",
    "        distances = np.insert(distances, (len(distances)-1), new_column, 1)\n",
    "\n",
    "\n",
    "    C.sort(key=sortFunction)\n",
    "    cluster_ids = [-1] * len(D)\n",
    "    for i, cluster in enumerate(C):\n",
    "        for point in cluster:\n",
    "            cluster_ids[point] = i\n",
    "\n",
    "    return cluster_ids\n",
    "\n",
    "def sortFunction(elem):\n",
    "    return min(elem)\n",
    "\n",
    "def lanceWilliamsParams(dist, n_i, n_j, n_r):\n",
    "    if dist == 'single':\n",
    "        return (1/2, 1/2, 0, -1/2)\n",
    "    elif dist == 'complete':\n",
    "        return (1/2, 1/2, 0, 1/2)\n",
    "    elif dist == 'groupavg':\n",
    "        return ((n_i/(n_i+n_j)), (n_j/(n_i+n_j)), 0, 0)\n",
    "    elif dist == 'meandist':\n",
    "        return ((n_i/(n_i+n_j)), (n_j/(n_i+n_j)), (-(n_i*n_j)/((n_i+n_j)**2)), 0)\n",
    "    elif dist == 'ward':\n",
    "        return (((n_i+n_r)/(n_i+n_j+n_r)), ((n_j+n_r)/(n_i+n_j+n_r)), (-n_r/(n_i+n_j+n_r)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]]\n",
      "[[ 0  2  4]\n",
      " [10 12 14]\n",
      " [20 22 24]]\n",
      "[[ 0  2  4]\n",
      " [10 12 14]\n",
      " [20 22 24]\n",
      " [ 1  2  3]]\n",
      "[1, 2, 3, 4]\n",
      "[[ 0  2  4  1]\n",
      " [10 12 14  2]\n",
      " [20 22 24  3]\n",
      " [ 1  2  3  4]]\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(25).reshape(5,5)\n",
    "\n",
    "print(A)\n",
    "A = np.delete(A, [1,3], 0)\n",
    "A = np.delete(A, [1,3], 1)\n",
    "print(A)\n",
    "\n",
    "col = [1,2,3]\n",
    "A = np.insert(A, len(A), col,0)\n",
    "print(A)\n",
    "\n",
    "col.append(4)\n",
    "print(col)\n",
    "A = np.insert(A, (len(A)-1), col,1)\n",
    "print(A)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa/setosa: OK\n",
      "setosa/versicolor: OK\n",
      "setosa/virginica: OK\n",
      "versicolor/setosa: OK\n",
      "versicolor/versicolor: OK\n",
      "versicolor/virginica: OK\n",
      "virginica/setosa: OK\n",
      "virginica/versicolor: OK\n",
      "virginica/virginica: OK\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'agglomerativeClusteringLW' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Universidad\\Sexto\\BI\\bi-sheet3\\sheet7\\Cifuentes-Cely-Perez_BISheet#7.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Universidad/Sexto/BI/bi-sheet3/sheet7/Cifuentes-Cely-Perez_BISheet%237.ipynb#X32sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mfor\u001b[39;00m pair \u001b[39min\u001b[39;00m [(\u001b[39m\"\u001b[39m\u001b[39msingle\u001b[39m\u001b[39m\"\u001b[39m, singleLink), (\u001b[39m\"\u001b[39m\u001b[39mcomplete\u001b[39m\u001b[39m\"\u001b[39m, completeLink), (\u001b[39m\"\u001b[39m\u001b[39mgroupavg\u001b[39m\u001b[39m\"\u001b[39m, groupAverage), (\u001b[39m\"\u001b[39m\u001b[39mward\u001b[39m\u001b[39m\"\u001b[39m, ward)]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Universidad/Sexto/BI/bi-sheet3/sheet7/Cifuentes-Cely-Perez_BISheet%237.ipynb#X32sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     C_ac \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(agglomerativeClustering(D, pair[\u001b[39m1\u001b[39m], k\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Universidad/Sexto/BI/bi-sheet3/sheet7/Cifuentes-Cely-Perez_BISheet%237.ipynb#X32sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     C_aclw \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(try_unification(C_ac, agglomerativeClusteringLW(D, pair[\u001b[39m0\u001b[39m], k\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Universidad/Sexto/BI/bi-sheet3/sheet7/Cifuentes-Cely-Perez_BISheet%237.ipynb#X32sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     mismatches \u001b[39m=\u001b[39m C_ac \u001b[39m!=\u001b[39m C_aclw\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Universidad/Sexto/BI/bi-sheet3/sheet7/Cifuentes-Cely-Perez_BISheet%237.ipynb#X32sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39mprint\u001b[39m(pair[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m OK\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mcount_nonzero(mismatches) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39m FAILED. Difference in positions: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(np\u001b[39m.\u001b[39mwhere(mismatches)[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(C_ac[mismatches]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m vs \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(C_aclw[mismatches]))))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agglomerativeClusteringLW' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "'''\n",
    "  Tries to make clustering c2 equal to clustering c1 by renaming the cluster names.\n",
    "  If the clusterings are effectively equivalent, the output will be equal to c1.\n",
    "'''\n",
    "def try_unification(c1, c2):\n",
    "    v1 = list(np.unique(c1))\n",
    "    v2 = list(np.unique(c2))\n",
    "    new_vals = []\n",
    "    if len(c1) != len(c2):\n",
    "        print(\"Cannot unify clusterings of different lengths!\")\n",
    "        return None\n",
    "    if len(v1) != len(v2):\n",
    "        print(\"Cannot unify clusterings of different numbers of clusters!\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    # use different symbols for clusterings\n",
    "    i = 0\n",
    "    for v in v2:\n",
    "        c = \"v\" + str(i)\n",
    "        while c in v1:\n",
    "            i +=1\n",
    "            c = \"v\" + str(i)\n",
    "        new_vals.append(c)\n",
    "        i += 1\n",
    "    c_new = [new_vals[v2.index(i)] for i in c2]\n",
    "    \n",
    "    # replace occurrences\n",
    "    targets = []\n",
    "    for symbol in new_vals:\n",
    "        first_index = c_new.index(symbol)\n",
    "        replace_symbol = None\n",
    "        for v in c1:\n",
    "            if not v in targets:\n",
    "                replace_symbol = v\n",
    "                break\n",
    "        if replace_symbol in targets:\n",
    "            print(\"Warning: No unification possible, the symbol \" + replace_symbol + \" has already been addressed before!\")\n",
    "            return None\n",
    "        \n",
    "        c_new = [replace_symbol if v == symbol else v for v in c_new]\n",
    "        targets.append(replace_symbol)\n",
    "    return c_new\n",
    "\n",
    "# Test Complete Link on Iris (PCA)\n",
    "dfIris = pd.read_csv(\"iris.csv\")\n",
    "DIris = PCA(n_components=2).fit_transform(dfIris.values[:,:4])\n",
    "labelsIris = list(pd.unique(dfIris[\"species\"]))\n",
    "C_perfect = np.array([labelsIris.index(l) for l in dfIris[\"species\"]])\n",
    "C_iris = np.array(try_unification(C_perfect, agglomerativeClustering(DIris, completeLink, k=3)))\n",
    "M_expected = np.array([[50, 0, 0], [0, 14, 49], [0, 36, 1]]) # according to slide 13\n",
    "for i in range(3):\n",
    "    cond1 = C_iris == i\n",
    "    for j in range(3):\n",
    "        cond2 = C_perfect == j\n",
    "        cnt_combo = np.count_nonzero(cond1 & cond2)\n",
    "        print(labelsIris[i] + \"/\" + labelsIris[j] + \": \" + (\"OK\" if cnt_combo == M_expected[i,j] else \"FAILED. Expected \" + str(M_expected[i,j]) + \" but saw \" + str(cnt_combo)))\n",
    "\n",
    "# Test Coincidence of Standard and Lance-Williams\n",
    "for D in [DIris, pd.get_dummies(pd.read_csv(\"Mall_Customers.csv\")).values]:\n",
    "    for pair in [(\"single\", singleLink), (\"complete\", completeLink), (\"groupavg\", groupAverage), (\"ward\", ward)]:\n",
    "        C_ac = np.array(agglomerativeClustering(D, pair[1], k=3))\n",
    "        C_aclw = np.array(try_unification(C_ac, agglomerativeClusteringLW(D, pair[0], k=3)))\n",
    "        mismatches = C_ac != C_aclw\n",
    "        print(pair[0] + (\" OK\" if np.count_nonzero(mismatches) == 0 else (\" FAILED. Difference in positions: \" + str(np.where(mismatches)[0]) + \": \" + str(C_ac[mismatches]) + \" vs \" + str(C_aclw[mismatches]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mall = pd.read_csv(\"Mall_Customers.csv\")\n",
    "\n",
    "#k=5\n",
    "#Run Aglomerative Clustering with Single Link\n",
    "\n",
    "#Run Aglomerative Clustering with Group Average\n",
    "\n",
    "#Run Aglomerative Clustering LW with Single Link\n",
    "\n",
    "#Run Aglomerative Clustering LW with Group Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestProjection(A, C, targetdims=2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 6x2 for every dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
