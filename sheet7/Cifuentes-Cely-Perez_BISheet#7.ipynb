{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from representatives import kMeans # you can use this kMeans in Ex. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerativeClustering(D, dist, k=1):\n",
    "    C = [[i] for i in range(len(D))]\n",
    "\n",
    "    while len(C) > k:\n",
    "        distances = np.zeros((len(C), len(C)))\n",
    "        for i in range(len(C)):\n",
    "            for j in range(i + 1, len(C)):\n",
    "                distances[i][j] = dist(D, C[i], C[j])\n",
    "                distances[j][i] = distances[i][j]\n",
    "\n",
    "        min_dist = np.inf\n",
    "        min_i, min_j = None, None\n",
    "\n",
    "        for i in range(len(C)):\n",
    "            for j in range(i + 1, len(C)):\n",
    "                if distances[i][j] < min_dist:\n",
    "                    min_dist = distances[i][j]\n",
    "                    min_i, min_j = i, j\n",
    "\n",
    "        Ci, Cj = C[min_i], C[min_j]\n",
    "        Cij = []\n",
    "        Cij.extend(Ci)\n",
    "        Cij.extend(Cj)\n",
    "\n",
    "        C.remove(Ci)\n",
    "        C.remove(Cj)\n",
    "        C.append(Cij)\n",
    "\n",
    "    C.sort(key=sortFunction)\n",
    "    cluster_ids = [-1] * len(D)\n",
    "    for i, cluster in enumerate(C):\n",
    "        for point in cluster:\n",
    "            cluster_ids[point] = i\n",
    "\n",
    "    return cluster_ids\n",
    "\n",
    "def sortFunction(elem):\n",
    "    return min(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleLink(D, Ci, Cj):\n",
    "    min_dist = np.inf\n",
    "    for i in Ci:\n",
    "        for j in Cj:\n",
    "            dist_ij = np.linalg.norm(D[i] - D[j])\n",
    "            if dist_ij < min_dist:\n",
    "                min_dist = dist_ij\n",
    "    return min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeLink(D, Ci, Cj):\n",
    "    max_dist = 0\n",
    "    for i in Ci:\n",
    "        for j in Cj:\n",
    "            dist_ij = np.linalg.norm(D[i] - D[j])\n",
    "            if dist_ij > max_dist:\n",
    "                max_dist = dist_ij\n",
    "    return max_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupAverage(D, Ci, Cj):\n",
    "    distance_sum = 0\n",
    "\n",
    "    D_i = [D[i] for i in Ci]\n",
    "    D_j = [D[i] for i in Cj]\n",
    "\n",
    "    for point_i in D_i:\n",
    "        for point_j in D_j:\n",
    "            distance_sum += np.linalg.norm(point_i - point_j)\n",
    "\n",
    "    return distance_sum / (len(D_i) * len(D_j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanDistance(D, Ci, Cj):\n",
    "    D_i = [D[i] for i in Ci]\n",
    "    D_j = [D[i] for i in Cj]\n",
    "\n",
    "    miu_i = np.average(D_i, axis=0)\n",
    "    miu_j = np.average(D_j, axis=0)\n",
    "\n",
    "    return np.linalg.norm(miu_j - miu_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ward(D, Ci, Cj):\n",
    "    D_i = [D[i] for i in Ci]\n",
    "    D_j = [D[i] for i in Cj]\n",
    "\n",
    "    miu_i = np.average(D_i, axis=0)\n",
    "    miu_j = np.average(D_j, axis=0)\n",
    "\n",
    "    mean_distance = np.linalg.norm(miu_i - miu_j)\n",
    "\n",
    "    n_i = len(D_i)\n",
    "    n_j = len(D_j)\n",
    "\n",
    "    return (((n_i * n_j) / (n_i + n_j)) * (mean_distance**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import ward\n",
    "\n",
    "agglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglomerativeClusteringLW(D, dist, k=1):\n",
    "    C = [[i] for i in range(len(D))]\n",
    "\n",
    "    distances = np.zeros((len(C), len(C)))\n",
    "    for i in range(len(C)):\n",
    "        for j in range(i + 1, len(C)):\n",
    "            distances[i][j] = np.linalg.norm(D[i] - D[j])\n",
    "            distances[j][i] = distances[i][j]\n",
    "\n",
    "\n",
    "    while len(C) > k:\n",
    "        min_dist = np.inf\n",
    "        min_i, min_j = None, None\n",
    "\n",
    "        for i in range(len(C)):\n",
    "            for j in range(i + 1, len(C)):\n",
    "                if distances[i][j] < min_dist:\n",
    "                    min_dist = distances[i][j]\n",
    "                    min_i, min_j = i, j\n",
    "\n",
    "        Ci, Cj = C[min_i], C[min_j]\n",
    "        Cij = []\n",
    "        Cij.extend(Ci)\n",
    "        Cij.extend(Cj)\n",
    "\n",
    "        C.remove(Ci)\n",
    "        C.remove(Cj)\n",
    "        C.append(Cij)\n",
    "\n",
    "        n_i = len(Ci)\n",
    "        n_j = len(Cj)\n",
    "        n_r = 0\n",
    "\n",
    "        new_column = []\n",
    "        for r in range(len(distances)):\n",
    "            if r != min_i and r != min_j:\n",
    "                n_r = len(C[r-2])\n",
    "                a_i, a_j, b, gamma = lanceWilliamsParams(dist, n_i, n_j, n_r)\n",
    "                \n",
    "                new_distance = a_i * distances[min_i][r] + a_j * distances[min_j][r] + b * distances[min_i][min_j] + gamma * np.abs(distances[min_i][r] - distances[min_j][r])\n",
    "                new_column.append(new_distance)\n",
    "\n",
    "        distances = np.delete(distances, [min_i,min_j], 0)\n",
    "        distances = np.delete(distances, [min_i,min_j], 1)\n",
    "\n",
    "        distances = np.insert(distances, len(distances), new_column, 0)\n",
    "        new_column.append(0)\n",
    "        distances = np.insert(distances, (len(distances)-1), new_column, 1)\n",
    "\n",
    "\n",
    "    C.sort(key=sortFunction)\n",
    "    cluster_ids = [-1] * len(D)\n",
    "    for i, cluster in enumerate(C):\n",
    "        for point in cluster:\n",
    "            cluster_ids[point] = i\n",
    "\n",
    "    return cluster_ids\n",
    "\n",
    "def sortFunction(elem):\n",
    "    return min(elem)\n",
    "\n",
    "def lanceWilliamsParams(dist, n_i, n_j, n_r):\n",
    "    if dist == 'single':\n",
    "        return (1/2, 1/2, 0, -(1/2))\n",
    "    elif dist == 'complete':\n",
    "        return (1/2, 1/2, 0, 1/2)\n",
    "    elif dist == 'groupavg':\n",
    "        return ((n_i/(n_i+n_j)), (n_j/(n_i+n_j)), 0, 0)\n",
    "    elif dist == 'meandist':\n",
    "        return ((n_i/(n_i+n_j)), (n_j/(n_i+n_j)), (-(n_i*n_j)/((n_i+n_j)**2)), 0)\n",
    "    elif dist == 'ward':\n",
    "        return (((n_i+n_r)/(n_i+n_j+n_r)), ((n_j+n_r)/(n_i+n_j+n_r)), (-n_r/(n_i+n_j+n_r)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa/setosa: OK\n",
      "setosa/versicolor: OK\n",
      "setosa/virginica: OK\n",
      "versicolor/setosa: OK\n",
      "versicolor/versicolor: OK\n",
      "versicolor/virginica: OK\n",
      "virginica/setosa: OK\n",
      "virginica/versicolor: OK\n",
      "virginica/virginica: OK\n",
      "single OK\n",
      "complete OK\n",
      "groupavg OK\n",
      "ward FAILED. Difference in positions: [ 77 110 134]: [2 2 2] vs [1 1 1]\n",
      "single OK\n",
      "complete OK\n",
      "groupavg OK\n",
      "ward FAILED. Difference in positions: [124 132 142]: [2 2 2] vs [1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "'''\n",
    "  Tries to make clustering c2 equal to clustering c1 by renaming the cluster names.\n",
    "  If the clusterings are effectively equivalent, the output will be equal to c1.\n",
    "'''\n",
    "def try_unification(c1, c2):\n",
    "    v1 = list(np.unique(c1))\n",
    "    v2 = list(np.unique(c2))\n",
    "    new_vals = []\n",
    "    if len(c1) != len(c2):\n",
    "        print(\"Cannot unify clusterings of different lengths!\")\n",
    "        return None\n",
    "    if len(v1) != len(v2):\n",
    "        print(\"Cannot unify clusterings of different numbers of clusters!\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    # use different symbols for clusterings\n",
    "    i = 0\n",
    "    for v in v2:\n",
    "        c = \"v\" + str(i)\n",
    "        while c in v1:\n",
    "            i +=1\n",
    "            c = \"v\" + str(i)\n",
    "        new_vals.append(c)\n",
    "        i += 1\n",
    "    c_new = [new_vals[v2.index(i)] for i in c2]\n",
    "    \n",
    "    # replace occurrences\n",
    "    targets = []\n",
    "    for symbol in new_vals:\n",
    "        first_index = c_new.index(symbol)\n",
    "        replace_symbol = None\n",
    "        for v in c1:\n",
    "            if not v in targets:\n",
    "                replace_symbol = v\n",
    "                break\n",
    "        if replace_symbol in targets:\n",
    "            print(\"Warning: No unification possible, the symbol \" + replace_symbol + \" has already been addressed before!\")\n",
    "            return None\n",
    "        \n",
    "        c_new = [replace_symbol if v == symbol else v for v in c_new]\n",
    "        targets.append(replace_symbol)\n",
    "    return c_new\n",
    "\n",
    "# Test Complete Link on Iris (PCA)\n",
    "dfIris = pd.read_csv(\"iris.csv\")\n",
    "DIris = PCA(n_components=2).fit_transform(dfIris.values[:,:4])\n",
    "labelsIris = list(pd.unique(dfIris[\"species\"]))\n",
    "C_perfect = np.array([labelsIris.index(l) for l in dfIris[\"species\"]])\n",
    "C_iris = np.array(try_unification(C_perfect, agglomerativeClustering(DIris, completeLink, k=3)))\n",
    "M_expected = np.array([[50, 0, 0], [0, 14, 49], [0, 36, 1]]) # according to slide 13\n",
    "for i in range(3):\n",
    "    cond1 = C_iris == i\n",
    "    for j in range(3):\n",
    "        cond2 = C_perfect == j\n",
    "        cnt_combo = np.count_nonzero(cond1 & cond2)\n",
    "        print(labelsIris[i] + \"/\" + labelsIris[j] + \": \" + (\"OK\" if cnt_combo == M_expected[i,j] else \"FAILED. Expected \" + str(M_expected[i,j]) + \" but saw \" + str(cnt_combo)))\n",
    "\n",
    "# Test Coincidence of Standard and Lance-Williams\n",
    "for D in [DIris, pd.get_dummies(pd.read_csv(\"Mall_Customers.csv\")).values]:\n",
    "    for pair in [(\"single\", singleLink), (\"complete\", completeLink), (\"groupavg\", groupAverage), (\"ward\", ward)]:\n",
    "        C_ac = np.array(agglomerativeClustering(D, pair[1], k=3))\n",
    "        C_aclw = np.array(try_unification(C_ac, agglomerativeClusteringLW(D, pair[0], k=3)))\n",
    "        mismatches = C_ac != C_aclw\n",
    "        print(pair[0] + (\" OK\" if np.count_nonzero(mismatches) == 0 else (\" FAILED. Difference in positions: \" + str(np.where(mismatches)[0]) + \": \" + str(C_ac[mismatches]) + \" vs \" + str(C_aclw[mismatches]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mall = pd.read_csv(\"Mall_Customers.csv\")\n",
    "\n",
    "#k=5\n",
    "#Run Aglomerative Clustering with Single Link\n",
    "\n",
    "#Run Aglomerative Clustering with Group Average\n",
    "\n",
    "#Run Aglomerative Clustering LW with Single Link\n",
    "\n",
    "#Run Aglomerative Clustering LW with Group Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestProjection(A, C, targetdims=2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot 6x2 for every dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
