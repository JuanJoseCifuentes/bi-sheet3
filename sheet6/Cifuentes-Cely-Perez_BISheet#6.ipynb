{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistances(A):\n",
    "\n",
    "  if type(A) is not np.ndarray:\n",
    "    A = A.to_numpy()\n",
    "\n",
    "  n = A.shape[0]\n",
    "  D = np.zeros((n, n))\n",
    "  for i in range(n):\n",
    "    for j in range(i + 1, n):\n",
    "      D[i][j] = np.linalg.norm(A[i] - A[j])\n",
    "      D[j][i] = D[i][j]\n",
    "  return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getW(D, U, V):\n",
    "    total_weight = 0.0\n",
    "    \n",
    "    for u in U:\n",
    "        for v in V:\n",
    "            total_weight += D[u][v]\n",
    "    \n",
    "    return total_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWIn(D, C):\n",
    "    win = 0.0\n",
    "\n",
    "    cluters_set = list(set(C))\n",
    "    for cluster in cluters_set:\n",
    "        indices = np.where(np.array(C) == cluster)[0]\n",
    "        win += getW(D, indices.tolist(), indices.tolist())\n",
    "    return (win/2).round()\n",
    "\n",
    "def getWOut(D, C):\n",
    "    wout = 0.0\n",
    "    for cluster in set(C):\n",
    "        cluster_indices = np.where(np.array(C) == cluster)[0]\n",
    "        other_indices = np.where(np.array(C) != cluster)[0]\n",
    "        wout += getW(D, cluster_indices.tolist(), other_indices.tolist())\n",
    "    return (wout/2).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNIn(C):\n",
    "    nin = 0\n",
    "    for cluster in set(C):\n",
    "        cluster_indices = np.where(np.array(C) == cluster)[0]\n",
    "        nin += len(cluster_indices) * (len(cluster_indices) - 1) // 2\n",
    "    return nin\n",
    "\n",
    "def getNOut(C):\n",
    "    n = len(C)\n",
    "    nout = n * (n - 1) // 2 - getNIn(C)\n",
    "    return nout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBetaCV(A, C):\n",
    "    D = getDistances(A=A)\n",
    "    w_in = getWIn(D=D,C=C)\n",
    "    n_in = getNIn(C=C)\n",
    "    w_out = getWOut(D=D,C=C)\n",
    "    n_out = getNOut(C=C)\n",
    "\n",
    "    return (w_in / n_in)/(w_out / n_out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCIndex(A, C):\n",
    "    D = getDistances(A=A)\n",
    "    w_in = getWIn(D=D,C=C)\n",
    "    n_in = getNIn(C=C)\n",
    "\n",
    "    w_sorted = np.sort((np.tril(D)).flatten())\n",
    "\n",
    "    first_index = 0\n",
    "    while w_sorted[first_index] == 0:\n",
    "        first_index += 1\n",
    "        \n",
    "    w_min = sum(w_sorted[:(n_in + first_index)])\n",
    "    w_max = sum(w_sorted[len(w_sorted) - n_in:])\n",
    "\n",
    "    return (w_in - w_min)/(w_max - w_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalizedCut(A, C):\n",
    "    nc_list = 0\n",
    "\n",
    "    D = getDistances(A=A)\n",
    "\n",
    "    index_set = list(set(C))\n",
    "    index_lists = []\n",
    "\n",
    "    for index in index_set:\n",
    "        index_list = []\n",
    "        for i, label in enumerate(C):\n",
    "            if label == index:\n",
    "                index_list.append(i)\n",
    "\n",
    "        index_lists.append(index_list)\n",
    "\n",
    "    for i, index_i in enumerate(index_set):\n",
    "        w_ci_else = 0\n",
    "        vol_ci = 0\n",
    "        for j, index_j in enumerate(index_set):\n",
    "            w = getW(D=D, U=index_lists[i], V=index_lists[j])\n",
    "            if index_i != index_j:\n",
    "                w_ci_else += w\n",
    "                vol_ci += w\n",
    "            else:\n",
    "                vol_ci += w\n",
    "\n",
    "        nc_list += w_ci_else / vol_ci\n",
    "\n",
    "    return nc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDunn(A, C):\n",
    "    D = getDistances(A=A)\n",
    "\n",
    "    mask = np.zeros_like(D)\n",
    "\n",
    "    n = len(C)\n",
    "\n",
    "    for i in range(n):\n",
    "        mask[i][i] = True\n",
    "        for j in range(i + 1, n):\n",
    "            if C[i] == C[j]:\n",
    "                mask[i][j] = True\n",
    "                mask[j][i] = True\n",
    "            else:\n",
    "                mask[i][j] = False\n",
    "                mask[j][i] = False\n",
    "\n",
    "    w_in = np.where(mask,D,-1)\n",
    "    w_max_in = w_in.max()\n",
    "\n",
    "    w_out = np.where(np.logical_not(mask), D, np.inf)\n",
    "    w_out = np.sort(w_out.flatten())\n",
    "\n",
    "    w_min_out = 0\n",
    "    i = 0\n",
    "    while w_min_out == 0:\n",
    "        w_min_out = w_out[i]\n",
    "\n",
    "    return w_min_out / w_max_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDaviesBouldin(A, C):\n",
    "    if type(A) is not np.ndarray:\n",
    "        A = A.to_numpy()\n",
    "\n",
    "    db_list = []\n",
    "\n",
    "    indexes = list(set(C))\n",
    "    k = len(indexes)\n",
    "\n",
    "    cluster_lens = [0] * k\n",
    "    cluster_means = []\n",
    "    cluster_dispersion = []\n",
    "\n",
    "    for index in C:\n",
    "        cluster_lens[indexes.index(index)] += 1\n",
    "\n",
    "    for i, index in enumerate(indexes):\n",
    "        data_in_c = []\n",
    "        for j, point_index in enumerate(C):\n",
    "            if point_index == index:\n",
    "                data_in_c.append(A[j])\n",
    "\n",
    "        mean = sum(data_in_c) / cluster_lens[i]\n",
    "        cluster_means.append(mean)\n",
    "\n",
    "        var = 0\n",
    "        for data in data_in_c:\n",
    "            var += (np.linalg.norm(data - mean)) ** 2\n",
    "        var = var / cluster_lens[i]\n",
    "        disp = var ** 0.5\n",
    "        cluster_dispersion.append(disp)\n",
    "\n",
    "    for i in range(k):\n",
    "        temp = []\n",
    "        for j in range(k):\n",
    "            if i != j:\n",
    "                db = (cluster_dispersion[i] + cluster_dispersion[j]) / np.linalg.norm(cluster_means[i] - cluster_means[j])\n",
    "                temp.append(db)\n",
    "\n",
    "        db_list.append(max(temp))\n",
    "\n",
    "    return (1/k) * sum(db_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSilhouette(A, C):\n",
    "    if type(A) is not np.ndarray:\n",
    "        A = A.to_numpy()\n",
    "\n",
    "    si_list = []\n",
    "\n",
    "    indexes = list(set(C))\n",
    "    index_lists = []\n",
    "\n",
    "    #construye una lista que tiene en cada index j otra lista con los index de las variables en A que pertenecen a cada cluster j\n",
    "    for index in indexes:\n",
    "        index_list = []\n",
    "        for i, label in enumerate(C):\n",
    "            if label == index:\n",
    "                index_list.append(i)\n",
    "\n",
    "        index_lists.append(index_list)\n",
    "\n",
    "    for i, cluster_name in enumerate(C):\n",
    "        current_index = indexes.index(cluster_name)\n",
    "        \n",
    "        weights = []\n",
    "        for j, index in enumerate(indexes):\n",
    "            if index != cluster_name:\n",
    "                weights.append((getW(D=getDistances(A=A), U=index_lists[current_index], V=index_lists[j]), index))\n",
    "\n",
    "        closest_cluster = (np.inf, -1)\n",
    "        for weight, clust_id in weights:\n",
    "            if weight < closest_cluster[0]:\n",
    "                closest_cluster = (weight,clust_id)\n",
    "\n",
    "        mean_in = 0\n",
    "        mean_min_out = 0\n",
    "        in_len = 0\n",
    "        min_out_len = 0\n",
    "\n",
    "        for j in range(len(C)):\n",
    "            if i != j: \n",
    "                if C[i] == C[j]:\n",
    "                    mean_in += np.linalg.norm(A[i] - A[j])\n",
    "                    in_len += 1\n",
    "                elif C[j] == closest_cluster[1]:  \n",
    "                        mean_min_out += np.linalg.norm(A[i] - A[j])\n",
    "                        min_out_len += 1\n",
    "\n",
    "        mean_in = mean_in/(in_len-1)\n",
    "        mean_min_out = mean_min_out/min_out_len\n",
    "\n",
    "        si = (mean_min_out - mean_in) / max([mean_min_out,mean_in])\n",
    "        si_list.append(si)\n",
    "\n",
    "    return (1/len(si_list)) * sum(si_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetric(A, C, metric):\n",
    "    if metric == \"beta\":\n",
    "        return getBetaCV(A=A, C=C)\n",
    "    elif metric == \"cindex\":\n",
    "        return getCIndex(A=A, C=C)\n",
    "    elif metric == \"nc\":\n",
    "        return getNormalizedCut(A=A, C=C)\n",
    "    elif metric == \"dunn\":\n",
    "        return getDunn(A=A, C=C)\n",
    "    elif metric == \"db\":\n",
    "        return getDaviesBouldin(A=A, C=C)\n",
    "    elif metric == \"sil\":\n",
    "        return getSilhouette(A=A, C=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Weight Measures\n",
      "------------------\n",
      "W: ok\n",
      "WIn: ok\n",
      "WOut: ok\n",
      "NIn: ok\n",
      "NOut: ok\n"
     ]
    }
   ],
   "source": [
    "# Test weights\n",
    "import pandas as pd_test\n",
    "import numpy as np_test\n",
    "dfIrisTest = pd_test.read_csv(\"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\")\n",
    "A_Iris_Test = dfIrisTest[dfIrisTest.columns[:4]].astype(float)\n",
    "C_Iris_Test = dfIrisTest[dfIrisTest.columns[4]]\n",
    "D_Iris_Test = getDistances(A_Iris_Test)\n",
    "C1 = np.where(C_Iris_Test == 'setosa')[0]\n",
    "C2 = np.where(C_Iris_Test == 'versicolor')[0]\n",
    "C3 = np.where(C_Iris_Test == 'virginica')[0]\n",
    "CList = [C1, C2, C3]\n",
    "\n",
    "print (\"\\nTest Weight Measures\\n------------------\")\n",
    "expectedW = {\n",
    "    (0,1): 8246,\n",
    "    (0,2): 12056,\n",
    "    (1,2): 4606\n",
    "}\n",
    "wSummary = \"W: \"\n",
    "wFailed = False\n",
    "for i in range(3):\n",
    "    for j in range(i):\n",
    "        p1 = (i,j)\n",
    "        p2 = (j,i)\n",
    "        W1 = np_test.round(getW(D_Iris_Test, CList[i], CList[j]))\n",
    "        W2 = np_test.round(getW(D_Iris_Test, CList[j], CList[i]))\n",
    "        if W1 != W2:\n",
    "            if not wFailed:\n",
    "                wSummary += \"failed\"\n",
    "            wSummary += \"\\n\\tasymmetry of W: \" + str(W1) + \" != \" + str(W2)\n",
    "            wFailed = True\n",
    "        \n",
    "        if W1 != expectedW[p2]:\n",
    "            if not wFailed:\n",
    "                wSummary += \"failed\"\n",
    "            wSummary += \"\\n\\tunexpected value of W: \" + str(W1) + \" instead of expected \" + str(expectedW[p2])\n",
    "            wFailed = True\n",
    "if not wFailed:\n",
    "    wSummary += \"ok\"\n",
    "print(wSummary)\n",
    "expectedWIn = 3518\n",
    "expectedWOut = 24908\n",
    "expectedNIn = 3675\n",
    "expectedNOut = 7500\n",
    "print(\"WIn:\", \"ok\" if np_test.abs(np_test.round(getWIn(D_Iris_Test, C_Iris_Test)) - expectedWIn) < 2 else \"failed\")\n",
    "print(\"WOut:\", \"ok\" if np_test.abs(np_test.round(getWOut(D_Iris_Test, C_Iris_Test)) - expectedWOut) < 2 else \"failed\")\n",
    "print(\"NIn:\", \"ok\" if getNIn(C_Iris_Test) == 3675 else \"failed\")\n",
    "print(\"NOut:\", \"ok\" if getNOut(C_Iris_Test) == 7500 else \"failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics\n",
      "------------------\n",
      "beta:\t ok\n",
      "cindex:\t ok\n",
      "nc:\t ok\n",
      "dunn:\t ok\n",
      "db:\t ok\n",
      "sil:\t ok\n"
     ]
    }
   ],
   "source": [
    "# Test weights\n",
    "import pandas as pd_test\n",
    "import numpy as np_test\n",
    "dfIrisTest = pd_test.read_csv(\"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\")\n",
    "A_Iris_Test = dfIrisTest[dfIrisTest.columns[:4]].astype(float)\n",
    "C_Iris_Test = dfIrisTest[dfIrisTest.columns[4]]\n",
    "D_Iris_Test = getDistances(A_Iris_Test)\n",
    "\n",
    "# Test metrics\n",
    "print (\"\\nTest Metrics\\n------------------\")\n",
    "expected = {\n",
    "    \"beta\": 0.2882861014913346,\n",
    "    \"cindex\": 0.046803774122703735,\n",
    "    \"nc\": 2.6150343040385264,\n",
    "    \"dunn\": 0.05848053214719304,\n",
    "    \"db\": 0.8445815484442534,\n",
    "    \"sil\": 0.5032506980665507\n",
    "}\n",
    "for m in expected:\n",
    "    e = np.round(expected[m], 2)\n",
    "    a = getMetric(A_Iris_Test, C_Iris_Test, m)\n",
    "    a = np.round(a, 2) if not a is None else None\n",
    "    print(m + \":\\t\", \"ok\" if e == a else \"failed. Expected \" + str(e) + \" but saw \" + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMetrics(D,kmeans_eps,dbscan_configs,l=100):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotClusters(D,C,dimX,dimY,dimZ=None,ax=None):\n",
    " h=type(D)==pd.DataFrame\n",
    " W=D.columns[dimX]if h else dimX\n",
    " X=D.columns[dimY]if h else dimY\n",
    " b=D.columns[dimZ]if h and not dimZ is None else dimZ\n",
    " if type(D)==pd.DataFrame:\n",
    "  D=D.values\n",
    " x=np.unique(C)\n",
    " K=not dimZ is None\n",
    " if ax is None:\n",
    "  if K:\n",
    "   I=plt.figure()\n",
    "   ax=I.add_subplot(111,projection='3d')\n",
    "  else:\n",
    "   I,ax=plt.subplots()\n",
    " for ci in x:\n",
    "  f=np.where(C==ci)[0]\n",
    "  if K:\n",
    "   ax.scatter(D[f,dimX],D[f,dimY],D[f,dimZ])\n",
    "  else:\n",
    "   ax.scatter(D[f,dimX],D[f,dimY])\n",
    " ax.set_xlabel(W)\n",
    " ax.set_ylabel(X)\n",
    " if K:\n",
    "  ax.set_zlabel(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans(D,k,eps=0.01,mu=None,max_iter=20):\n",
    " d=D.shape[1]\n",
    " if mu is None:\n",
    "  mu=np.random.rand(k,d)*(np.max(D,axis=0)-np.min(D,axis=0))+np.min(D,axis=0)\n",
    " if type(mu)==list:\n",
    "  mu=np.array(mu)\n",
    " s=False\n",
    " g=0\n",
    " while not s:\n",
    "  C=[np.argmin([np.linalg.norm(mu[j]-x)for j in range(k)if not any(np.isnan(mu[j]))])for x in D]\n",
    "  n=np.zeros(mu.shape)\n",
    "  s=True\n",
    "  for i in range(k):\n",
    "   J=[D[j]for j in range(len(D))if C[j]==i]\n",
    "   if len(J)>0:\n",
    "    n[i]=np.mean(J,axis=0)\n",
    "   else:\n",
    "    n[i]=np.random.rand(1,d)*(np.max(D,axis=0)-np.min(D,axis=0))+np.min(D,axis=0)\n",
    "   if np.linalg.norm(mu[i]-n[i])>eps:\n",
    "    s=False\n",
    "  mu=n\n",
    "  g+=1\n",
    "  if g>=max_iter:\n",
    "   s=True\n",
    " return C,mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = pd.read_csv(\"iris.csv\")\n",
    "df_flights = pd.read_csv(\"delayedflights-small.csv\")\n",
    "df_mall = pd.read_csv(\"Mall_Customers.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
