{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.optimize import minimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eclat(db, minsup):\n",
    "    def generate_frequent_itemsets(P, minsup, F):\n",
    "        for i, p_i in enumerate(P):\n",
    "            Xa, t_Xa = p_i\n",
    "            if not isinstance(Xa, list):\n",
    "                Xa = [Xa]\n",
    "            F.append((Xa, len(t_Xa)))\n",
    "            Pa = []\n",
    "            for j in range(i + 1, len(P)):\n",
    "                Xb, t_Xb = P[j]\n",
    "                if not isinstance(Xb, list):\n",
    "                    Xb = [Xb]\n",
    "                if j > i:\n",
    "                    Xab = list(set(Xa).union(set(Xb)))\n",
    "                    Xab.sort()\n",
    "                    t_Xab = t_Xa.intersection(t_Xb)\n",
    "                    if len(t_Xab) >= minsup:\n",
    "                        Pa.append((Xab, t_Xab))\n",
    "            if len(Pa) != 0:\n",
    "                generate_frequent_itemsets(Pa, minsup, F)\n",
    "\n",
    "    P = {}\n",
    "    for i in range(len(db)):\n",
    "        for item in db[i]:\n",
    "            if item in P:\n",
    "                P[item].add(i)\n",
    "            else:\n",
    "                P[item] = {i}\n",
    "    P = list(P.items())\n",
    "    \n",
    "    condition = lambda x: len(x[1]) >= minsup\n",
    "    P = [item for item in P if condition(item)]\n",
    "\n",
    "    P = sorted(P, key=lambda x: x[0])\n",
    "    F = []\n",
    "    \n",
    "    generate_frequent_itemsets(P, minsup, F)\n",
    "\n",
    "    return [(F[i][0], F[i][1]) for i in range(len(F))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfidence(sup_xy, sup_x):\n",
    "    return sup_xy / sup_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLift(conf, sup_y, len_database):\n",
    "    rsup_y = sup_y / len_database\n",
    "    lift = conf / rsup_y\n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLeverage(sup_xy, sup_x, sup_y, len_database):\n",
    "    rsup_xy = sup_xy / len_database\n",
    "    rsup_x = sup_x / len_database\n",
    "    rsup_y = sup_y / len_database\n",
    "\n",
    "    leverage = rsup_xy - (rsup_x * rsup_y)\n",
    "    return leverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJaccard(sup_xy, sup_x, sup_y):\n",
    "    jaccard_denominator = sup_x + sup_y - sup_xy\n",
    "    jaccard = sup_xy / jaccard_denominator\n",
    "    return jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConviction(conf, sup_y, len_database):\n",
    "    rsup_y = sup_y / len_database\n",
    "    conviction_denominator = 1 - conf\n",
    "    conviction = (1 - rsup_y) / conviction_denominator\n",
    "    return conviction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOddsRatio(sup_xy, sup_x, sup_y, len_database):\n",
    "    sup_nox_y = sup_y - sup_xy\n",
    "    sup_x_noy = sup_x - sup_xy\n",
    "    sup_nox_noy = len_database - sup_xy - sup_nox_y - sup_x_noy\n",
    "\n",
    "    odds_denominator = sup_x_noy * sup_nox_y\n",
    "    odds = (sup_xy * sup_nox_noy) / odds_denominator\n",
    "    return odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStrongRulesFromFrequentSets(fsets, minconf, len_database):\n",
    "    strong_rules = []\n",
    "    fsets_sets = [item[0] for item in fsets]\n",
    "    fsets_supp = [item[1] for item in fsets]\n",
    "    for i, frequentSet in enumerate(fsets_sets):\n",
    "        if len(frequentSet) >= 2:\n",
    "            A = getSubsets(set=frequentSet)\n",
    "            while len(A) != 0:\n",
    "                X = A[-1]\n",
    "                A.remove(X)\n",
    "\n",
    "                sup_xy = fsets_supp[i]\n",
    "                \n",
    "                index_x = fsets_sets.index(X)\n",
    "                sup_x = fsets_supp[index_x]\n",
    "\n",
    "                conf = getConfidence(sup_xy, sup_x)\n",
    "                if conf >= minconf:\n",
    "                    #Y is the complement of X in the set frequentSet\n",
    "                    Y = list(frequentSet)\n",
    "                    for item in X:\n",
    "                        Y.remove(item)\n",
    "\n",
    "                    sup_y = fsets_supp[fsets_sets.index(Y)]\n",
    "\n",
    "                    rsup_xy = sup_xy / len_database\n",
    "                    lift = getLift(conf, sup_y, len_database)\n",
    "                    lev = getLeverage(sup_xy, sup_x, sup_y, len_database)\n",
    "                    jacc = getJaccard(sup_xy, sup_x, sup_y)\n",
    "                    conv = getConviction(conf, sup_y, len_database)\n",
    "                    odds = getOddsRatio(sup_xy, sup_x, sup_y, len_database)\n",
    "\n",
    "                    strong_rules.append((X, Y, (conf, lift, lev, conv, odds)))\n",
    "                else:\n",
    "                    if len(X) >= 2:\n",
    "                        W_sets = getSubsets(X)\n",
    "                        for W in W_sets:\n",
    "                            if W in A:\n",
    "                                A.remove(W)\n",
    "\n",
    "    return strong_rules\n",
    "\n",
    "def getSubsets(set):\n",
    "    subsets = []\n",
    "    x = len(set)\n",
    "    for i in range(1 << x):\n",
    "       subsets.append([set[j] for j in range(x) if (i & (1 << j))])\n",
    "\n",
    "    subsets.pop(-1)\n",
    "    subsets.pop(0)\n",
    "\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStrongRulesForDatabase(db, minsup, minconf):\n",
    "    fsets = eclat(db, minsup)\n",
    "\n",
    "    len_data = len(db)\n",
    "\n",
    "    strong_rules = getStrongRulesFromFrequentSets(fsets, minconf, len_data)\n",
    "    return strong_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_score(conf, lift, lev, conv, odds, weights):\n",
    "    total_score = np.average([conf, lift, lev, conv, odds], weights=weights, axis=0)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(weights, conf, lift, lev, conv, odds):\n",
    "    total_score = 0\n",
    "    for i in range(len(lift)):\n",
    "        score = calculate_weighted_score(conf[i], lift[i], lev[i], conv[i], odds[i], weights) #sup[i], conf[i], lift[i], lev[i], jacc[i], conv[i], odds[i], weights\n",
    "        total_score = total_score + score\n",
    "\n",
    "    total_score = total_score/len(lift)\n",
    "    return 0-total_score\n",
    "\n",
    "def optimize_hyperparameters(metrics):\n",
    "    bounds = [(0, 1)] * len(metrics)\n",
    "    initial_weights = [1/len(metrics)] * len(metrics)\n",
    "    \n",
    "    result = minimize(objective_function, initial_weights, args=metrics, bounds=bounds)\n",
    "\n",
    "    optimal_weights = result.x\n",
    "    return optimal_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    \"\"\"\n",
    "        This is the class to make recommendations.\n",
    "        The class must not require any mandatory arguments for initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.rules = {}\n",
    "        self.prices = {}\n",
    "        self.weights = []\n",
    "\n",
    "\n",
    "    def train(self, prices, database) -> None:\n",
    "        \"\"\"\n",
    "            allows the recommender to learn which items exist, which prices they have, and which items have been purchased together in the past\n",
    "            :param prices: a list of prices in USD for the items (the item ids are from 0 to the length of this list - 1)\n",
    "            :param database: a list of lists of item ids that have been purchased together. Every entry corresponds to one transaction\n",
    "            :return: the object should return itself here (this is actually important!)\n",
    "        \"\"\"\n",
    "        \n",
    "        rules_db = getStrongRulesForDatabase(db=database, minsup=0.002*len(database), minconf=0.1)\n",
    "        premises, conclusions, metrics = [], [], []\n",
    "\n",
    "        for rule in rules_db:\n",
    "            premises.append(tuple(rule[0]))\n",
    "            conclusions.append(tuple(rule[1]))\n",
    "            metrics.append(rule[2])\n",
    "        \n",
    "        print(len(metrics))\n",
    "        print(len(metrics[0]))\n",
    " \n",
    "        normalized_metrics = []\n",
    "        grouped_metrics = ()\n",
    "        for i in range(len(metrics[0])):\n",
    "            metric = [x[i] for x in metrics]\n",
    "            grouped_metrics = grouped_metrics + (metric,)\n",
    "            min_metric = min(metric)\n",
    "            max_metric = max(metric)\n",
    "                \n",
    "            normalized_metric = []\n",
    "            for meassure in metric:\n",
    "                normalized_meassure = (meassure - min_metric) / (max_metric - min_metric)\n",
    "                normalized_metric.append(normalized_meassure)\n",
    "            normalized_metrics.append(normalized_metric)\n",
    "\n",
    "        metrics = list(zip(*normalized_metrics))\n",
    "        \n",
    "        print(len(metrics))\n",
    "        print(len(metrics[0]))\n",
    "        \n",
    "        temp_rules = list(zip(premises,conclusions))\n",
    "        for i, rule in enumerate(temp_rules):\n",
    "            self.rules[rule] = metrics[i]\n",
    "\n",
    "        for i, price in enumerate(prices):\n",
    "            self.prices[i] = price\n",
    "        self.weights = optimize_hyperparameters(grouped_metrics)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_recommendations(self, cart:list, max_recommendations:int) -> list:\n",
    "        \"\"\"\n",
    "            makes a recommendation to a specific user\n",
    "            \n",
    "            :param cart: a list with the items in the cart\n",
    "            :param max_recommendations: maximum number of items that may be recommended\n",
    "            :return: list of at most `max_recommendations` items to be recommended\n",
    "        \"\"\"\n",
    "\n",
    "        rules = list(self.rules.keys())\n",
    "        premises, conclussions = [],[]\n",
    "        for rule in rules:\n",
    "            premises.append(list(rule[0]))\n",
    "            conclussions.append(list(rule[1]))\n",
    "\n",
    "        #Gets only the conclusions in which the cart is a subset or equal to the premise\n",
    "        possible_recommendations = []\n",
    "        for i, premise in enumerate(premises):\n",
    "            if (all(x in cart for x in premise)):\n",
    "                rule = (tuple(premise), tuple(conclussions[i]))\n",
    "                metrics = self.rules[rule]\n",
    "                \n",
    "                total_score = calculate_weighted_score(metrics[0], metrics[1], metrics[2],metrics[3],metrics[4],self.weights)\n",
    "                \n",
    "                possible_recommendations.append((conclussions[i], total_score))\n",
    "        possible_recommendations = sorted(possible_recommendations, key=lambda x:x[1])\n",
    "\n",
    "        #Gets the (at least) 10 best items according to our evaluation and sorts them by price\n",
    "        best_recommendations = []\n",
    "        best_recommendations_prices = []\n",
    "\n",
    "        for i in range(len(possible_recommendations)):\n",
    "            if len(best_recommendations) >= max_recommendations + 30:\n",
    "                break\n",
    "            \n",
    "            #Add the items in the best rule\n",
    "            for item in possible_recommendations[-1][0]:\n",
    "                if item not in best_recommendations:\n",
    "                    best_recommendations.append(item)\n",
    "                    best_recommendations_prices.append(self.prices[item])\n",
    "                possible_recommendations[-1][0].remove(item)\n",
    "                \n",
    "            possible_recommendations.pop(-1)\n",
    "        \n",
    "        best_recommendations = [x for _, x in sorted(zip(best_recommendations_prices, best_recommendations), key=lambda pair: pair[0])]\n",
    "\n",
    "        recommendations = []\n",
    "        i=0\n",
    "        while i < max_recommendations:\n",
    "            if len(best_recommendations) == 0:\n",
    "                break\n",
    "\n",
    "            if best_recommendations[-1] not in recommendations:\n",
    "                recommendations.append(best_recommendations.pop(-1))\n",
    "                i = i + 1\n",
    "            else:\n",
    "                best_recommendations.pop(-1)\n",
    "\n",
    "        if len(recommendations) > 0:\n",
    "            return recommendations\n",
    "        else:\n",
    "            return[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prices.json', 'r') as file:\n",
    "    prices = eval(file.read())\n",
    "\n",
    "with open('training_data.json', 'r') as file:\n",
    "    data = eval(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16036\n",
      "5\n",
      "16036\n",
      "5\n",
      "[57, 31, 18]\n",
      "[(0, 45.75), (1, 12.85), (2, 14.42), (3, 4.0), (4, 11.97), (5, 16.12), (6, 8.88), (7, 11.73), (8, 16.04), (9, 1.86), (10, 2.09), (11, 4.35), (12, 1.3), (13, 6.57), (14, 8.69), (15, 3.75), (16, 9.88), (17, 5.64), (18, 26.39), (19, 3.57), (20, 24.07), (21, 13.11), (22, 11.11), (23, 0.5), (24, 5.68), (25, 3.84), (26, 2.66), (27, 5.3), (28, 4.09), (29, 10.46), (30, 3.88), (31, 29.68), (32, 4.24), (33, 3.81), (34, 2.91), (35, 1.52), (36, 2.11), (37, 35.01), (38, 3.44), (39, 42.85), (40, 28.3), (41, 4.82), (42, 1.38), (43, 1.65), (44, 4.95), (45, 1.8), (46, 4.01), (47, 6.15), (48, 1.97), (49, 1.93), (50, 6.25), (51, 5.82), (52, 1.92), (53, 2.72), (54, 5.04), (55, 10.7), (56, 15.91), (57, 32.52), (58, 4.13), (59, 5.72), (60, 8.34), (61, 4.78), (62, 12.57), (63, 2.64), (64, 27.54), (65, 3.37), (66, 1.41), (67, 15.75), (68, 1.25), (69, 3.09), (70, 2.32), (71, 12.18), (72, 8.35), (73, 4.7), (74, 6.78), (75, 0.78), (76, 6.18), (77, 7.88), (78, 34.75), (79, 2.44), (80, 1.69), (81, 1.9), (82, 2.68), (83, 17.72), (84, 19.45), (85, 40.27), (86, 5.96), (87, 15.55), (88, 7.38), (89, 3.08), (90, 23.77), (91, 3.9), (92, 10.07), (93, 1.6), (94, 2.34), (95, 5.97), (96, 0.58), (97, 11.22), (98, 5.47)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "recommender = Recommender()\n",
    "recommender = recommender.train(prices=prices, database=data)\n",
    "\n",
    "carrito = [random.randint(0,99),random.randint(0,99),random.randint(0,99),random.randint(0,99),random.randint(0,99)]\n",
    "carrito = list(set(carrito))\n",
    "\n",
    "a = recommender.get_recommendations(cart=carrito, max_recommendations=3)\n",
    "print(a)\n",
    "print(list(zip(range(99), prices)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
