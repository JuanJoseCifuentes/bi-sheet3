{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numbers\n",
    "from scipy.linalg import eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = pd.read_csv('https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv')\n",
    "iris = iris_dataset.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9 3.5\n",
      "  3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2\n",
      "  3.5 3.1 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3\n",
      "  2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2 2.8\n",
      "  2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0 2.5\n",
      "  2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5 2.9\n",
      "  2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2\n",
      "  2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7 3.2\n",
      "  3.3 3.0 2.5 3.0 3.4 3.0]\n",
      " [1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4\n",
      "  1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2\n",
      "  1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0\n",
      "  4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0\n",
      "  4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0\n",
      "  4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3\n",
      "  5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0\n",
      "  4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9\n",
      "  5.7 5.2 5.0 5.2 5.4 5.1]]\n",
      "[[-0.99414596  0.10804539]\n",
      " [-0.10804539 -0.99414596]]\n"
     ]
    }
   ],
   "source": [
    "iris = iris_dataset.to_numpy()\n",
    "Xi1 = iris[:,1]\n",
    "Xj1 = iris[:,2]\n",
    "\n",
    "print(np.array([Xi1,Xj1]))\n",
    "example1 = np.array([Xi1,Xj1]).astype(float)\n",
    "cov1 = np.cov(example1)\n",
    "eigVals1, eigVecs1 = eig(cov1)\n",
    "\n",
    "print(eigVecs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.5 3.0 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.0 3.0 4.0 4.4 3.9\n",
      "  3.5 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.0 3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1\n",
      "  3.2 3.5 3.1 3.0 3.4 3.5 2.3 3.2 3.5 3.8 3.0 3.8 3.2 3.7 3.3 3.2 3.2 3.1\n",
      "  2.3 2.8 2.8 3.3 2.4 2.9 2.7 2.0 3.0 2.2 2.9 2.9 3.1 3.0 2.7 2.2 2.5 3.2\n",
      "  2.8 2.5 2.8 2.9 3.0 2.8 3.0 2.9 2.6 2.4 2.4 2.7 2.7 3.0 3.4 3.1 2.3 3.0\n",
      "  2.5 2.6 3.0 2.6 2.3 2.7 3.0 2.9 2.9 2.5 2.8 3.3 2.7 3.0 2.9 3.0 3.0 2.5\n",
      "  2.9 2.5 3.6 3.2 2.7 3.0 2.5 2.8 3.2 3.0 3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3\n",
      "  3.2 2.8 3.0 2.8 3.0 2.8 3.8 2.8 2.8 2.6 3.0 3.4 3.1 3.0 3.1 3.1 3.1 2.7\n",
      "  3.2 3.3 3.0 2.5 3.0 3.4 3.0]\n",
      " [4.199999999999999 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1\n",
      "  1.2 1.5 1.3 1.4 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5\n",
      "  1.5 1.4 1.5 1.2 1.3 1.5 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4\n",
      "  4.7 4.5 4.9 4.0 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1\n",
      "  4.5 3.9 4.8 4.0 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5\n",
      "  4.7 4.4 4.1 4.0 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6\n",
      "  5.8 6.6 4.5 6.3 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9\n",
      "  6.7 4.9 5.7 6.0 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4\n",
      "  5.6 5.1 5.1 5.9 5.7 5.2 5.0 5.2 5.4 5.1]]\n",
      "[[-0.99346248  0.11415913]\n",
      " [-0.11415913 -0.99346248]]\n"
     ]
    }
   ],
   "source": [
    "iris = iris_dataset.to_numpy()\n",
    "Xi2 = iris[:,1]\n",
    "Xj2 = iris[:,2]\n",
    "Xi2[0] = Xi2[0] * 3\n",
    "Xj2[0] = Xj2[0] * 3\n",
    "\n",
    "print(np.array([Xi2,Xj2]))\n",
    "example2 = np.array([Xi2,Xj2]).astype(float)\n",
    "cov2 = np.cov(example2)\n",
    "eigVals2, eigVecs2 = eig(cov2)\n",
    "\n",
    "print(eigVecs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def PCA(D, red):\n",
    "    \n",
    "    data_centralizada = D - np.mean(D, axis=0)\n",
    "    \n",
    "    # Matriz covarianza\n",
    "    cov_matrix = np.cov(data_centralizada, rowvar=False)\n",
    "    \n",
    "    # Eigenvalores de la matriz\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    \n",
    "    # Ordenar los más importantes\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "\n",
    "    #Determinar el número de dimensiones a retener en función de la fracción de varianza\n",
    "    total_variance = np.sum(eigenvalues)\n",
    "    if red < 1:\n",
    "        \n",
    "        retained_variance = red * total_variance\n",
    "        cum_variance = np.cumsum(eigenvalues)\n",
    "        num_dimensions = np.argmax(cum_variance >= retained_variance) + 1\n",
    "    elif isinstance(red, int) and red >= 1:\n",
    "        # Usar los que de red\n",
    "        num_dimensions = red\n",
    "    else:\n",
    "        raise ValueError(\"Valor inválido, recuerde que debe ser entero positivo.\")    \n",
    "    \n",
    "    # Usar los mayores de 'num_dimensions' eigenvectors\n",
    "    selected_eigenvectors = eigenvectors[:, :num_dimensions]\n",
    "    \n",
    "    # Datos reducidos (producto punto)\n",
    "    reduced_data = np.dot(data_centralizada, selected_eigenvectors)\n",
    "    \n",
    "    # Varianza explicada en los datos reducidos\n",
    "    #Varianza Explicada= Suma de todos los valores propios/Suma de los primeros k valores propios\n",
    "    varianza_explicada = np.sum(eigenvalues[:num_dimensions]) / total_variance\n",
    "    \n",
    "    return reduced_data, varianza_explicada\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = pd.read_csv(\"iris.csv\")\n",
    "df_baseball_numeric = pd.read_csv(\"baseball_numeric.csv\")\n",
    "df_faber = pd.read_csv(\"fabert.csv\")\n",
    "dfAmazon = pd.read_csv(\"amazon.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now do PCA for a reduction to 1, 2 and 3 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point #3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cats = pd.read_csv(\"noisy_cats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the categorical attribute with Bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot for the points of the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce the data to 1 dimensions, then scatter again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the data, reduce to 1 dimension again, then scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Centralize the columns, divide by the standard deviation, apply PCA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
