{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def PCA(D, red):\n",
    "    \n",
    "    data_centralizada = D - np.mean(D, axis=0)\n",
    "    \n",
    "    # Matriz covarianza\n",
    "    cov_matrix = np.cov(data_centralizada, rowvar=False)\n",
    "    \n",
    "    # Eigenvalores de la matriz\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    \n",
    "    # Ordenar los más importantes\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "\n",
    "    #Determinar el número de dimensiones a retener en función de la fracción de varianza\n",
    "    total_variance = np.sum(eigenvalues)\n",
    "    if red < 1:\n",
    "        \n",
    "        retained_variance = red * total_variance\n",
    "        cum_variance = np.cumsum(eigenvalues)\n",
    "        num_dimensions = np.argmax(cum_variance >= retained_variance) + 1\n",
    "    elif isinstance(red, int) and red >= 1:\n",
    "        # Usar los que de red\n",
    "        num_dimensions = red\n",
    "    else:\n",
    "        raise ValueError(\"Valor inválido, recuerde que debe ser entero positivo.\")    \n",
    "    \n",
    "    # Usar los mayores de 'num_dimensions' eigenvectors\n",
    "    selected_eigenvectors = eigenvectors[:, :num_dimensions]\n",
    "    \n",
    "    # Datos reducidos (producto punto)\n",
    "    reduced_data = np.dot(data_centralizada, selected_eigenvectors)\n",
    "    \n",
    "    # Varianza explicada en los datos reducidos\n",
    "    #Varianza Explicada= Suma de todos los valores propios/Suma de los primeros k valores propios\n",
    "    varianza_explicada = np.sum(eigenvalues[:num_dimensions]) / total_variance\n",
    "    \n",
    "    return reduced_data, varianza_explicada\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = pd.read_csv(\"iris.csv\")\n",
    "df_baseball_numeric = pd.read_csv(\"baseball_numeric.csv\")\n",
    "df_faber = pd.read_csv(\"fabert.csv\")\n",
    "dfAmazon = pd.read_csv(\"amazon.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now do PCA for a reduction to 1, 2 and 3 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point #3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cats = pd.read_csv(\"noisy_cats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the categorical attribute with Bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot for the points of the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce the data to 1 dimensions, then scatter again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the data, reduce to 1 dimension again, then scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Centralize the columns, divide by the standard deviation, apply PCA."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
